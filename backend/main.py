import os
import requests
from bs4 import BeautifulSoup
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def fetch_html_from_url(url: str) -> str:
    """æŒ‡å®šã—ãŸURLã‹ã‚‰HTMLã‚’å–å¾—ã™ã‚‹"""
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.text
    except requests.RequestException as e:
        print(f"âŒ URLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return ""

def extract_title_and_content(html: str) -> tuple[str, str]:
    """HTMLã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’æŠ½å‡ºã™ã‚‹"""
    soup = BeautifulSoup(html, "html.parser")

    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
    title = soup.title.string.strip() if soup.title else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"

    # æœ¬æ–‡ã‚’æŠ½å‡ºï¼ˆ<p>ã‚¿ã‚°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼‰
    paragraphs = soup.find_all("p")
    content = "\n".join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])

    return title, content

def update_supabase_with_extracted_data(row_id: int, title: str, content: str):
    """Supabaseã®websitesãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°ã™ã‚‹"""
    response = supabase.table("websites").update({
        "title": title,
        "content": content
    }).eq("id", row_id).execute()

    if response.data:
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«æˆåŠŸã—ã¾ã—ãŸ (ID: {row_id})")
    else:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ (ID: {row_id}): {response}")

def main():
    # ã™ã§ã«å‡¦ç†æ¸ˆã¿ã§ãªã„URLã®ã¿å–å¾—ï¼ˆtitleãŒnullã®ãƒ‡ãƒ¼ã‚¿ï¼‰
    response = supabase.table("websites").select("id, url").is_("title", None).execute()

    if response.data:
        for row in response.data:
            row_id = row["id"]
            url = row["url"]
            print(f"ğŸ” URLã‚’å‡¦ç†ä¸­: {url}")

            # HTMLã‚’å–å¾—ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’æŠ½å‡º
            html = fetch_html_from_url(url)
            if html:
                title, content = extract_title_and_content(html)
                print(f"ğŸ“Œ æŠ½å‡ºçµæœ: ã‚¿ã‚¤ãƒˆãƒ«: {title}")

                # Supabaseã®websitesãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
                update_supabase_with_extracted_data(row_id, title, content)
    else:
        print("âœ… ã™ã¹ã¦ã®URLãŒå‡¦ç†æ¸ˆã¿ã§ã™ã€‚")

if __name__ == "__main__":
    main()
